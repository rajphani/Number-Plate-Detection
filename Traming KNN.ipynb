{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"GHMzG1_QnHW0","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","import numpy as np\n","import operator\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ycvARf46nJ8B","colab_type":"code","colab":{}},"cell_type":"code","source":["MIN_CONTOUR_AREA = 100\n","\n","RESIZED_IMAGE_WIDTH = 20\n","RESIZED_IMAGE_HEIGHT = 30"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4EHztvXvnMwC","colab_type":"code","colab":{}},"cell_type":"code","source":["class ContourWithData():\n","\n","    # member variables ############################################################################\n","    npaContour = None           # contour\n","    boundingRect = None         # bounding rect for contour\n","    intRectX = 0                # bounding rect top left corner x location\n","    intRectY = 0                # bounding rect top left corner y location\n","    intRectWidth = 0            # bounding rect width\n","    intRectHeight = 0           # bounding rect height\n","    fltArea = 0.0               # area of contour\n","\n","    def calculateRectTopLeftPointAndWidthAndHeight(self):               # calculate bounding rect info\n","        [intX, intY, intWidth, intHeight] = self.boundingRect\n","        self.intRectX = intX\n","        self.intRectY = intY\n","        self.intRectWidth = intWidth\n","        self.intRectHeight = intHeight\n","\n","    def checkIfContourIsValid(self):                            # this is oversimplified, for a production grade program\n","        if self.fltArea < MIN_CONTOUR_AREA: return False        # much better validity checking would be necessary\n","        return True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5RpWOvIdnQGN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"c22d96fd-0e8e-44de-fcac-8366c889209c","executionInfo":{"status":"error","timestamp":1552205261834,"user_tz":-330,"elapsed":1211,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["allContoursWithData = []                # declare empty lists,\n","validContoursWithData = []              # we will fill these shortly\n","\n","try:\n","  npaClassifications = np.loadtxt(\"classifications.txt\", np.float32)                  # read in training classifications\n","  \n","except:\n","  print(\"error, unable to open classifications.txt, exiting program\\n\")\n","  os.system(\"pause\")\n","# end try\n","\n","try:\n","  npaFlattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)                 # read in training images\n","except:\n","  print(\"error, unable to open flattened_images.txt, exiting program\\n\")\n","# end try\n","\n","npaClassifications = npaClassifications.reshape((npaClassifications.size, 1))       # reshape numpy array to 1d, necessary to pass to call to train\n","\n","kNearest = cv2.ml.KNearest_create()                   # instantiate KNN object\n","\n","kNearest.train(npaFlattenedImages, cv2.ml.ROW_SAMPLE, npaClassifications)\n","\n","imgTestingNumbers = cv2.imread(\"test1.png\")          # read in testing numbers image\n","\n","if imgTestingNumbers is None:                           # if image was not read successfully\n","  print(\"error: image not read from file \\n\\n\")        # print error message to std out\n","  os.system(\"pause\")                                  # pause so user can see error message\n","                                                      # and exit function (which exits program)\n","    # end if\n","\n","imgGray = cv2.cvtColor(imgTestingNumbers, cv2.COLOR_BGR2GRAY)       # get grayscale image\n","imgBlurred = cv2.GaussianBlur(imgGray, (5,5), 0)                    # blur\n","\n","                                                        # filter image from grayscale to black and white\n","imgThresh = cv2.adaptiveThreshold(imgBlurred, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  cv2.THRESH_BINARY_INV, 11,2)                                    # constant subtracted from the mean or weighted mean\n","\n","imgThreshCopy = imgThresh.copy()        # make a copy of the thresh image, this in necessary b/c findContours modifies the image\n","\n","imgContours, npaContours, npaHierarchy = cv2.findContours(imgThreshCopy,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)   # compress horizontal, vertical, and diagonal segments and leave only their end points\n","\n","for npaContour in npaContours:                             # for each contour\n","  contourWithData = ContourWithData()                                             # instantiate a contour with data object\n","  contourWithData.npaContour = npaContour                                         # assign contour to contour with data\n","  contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     # get the bounding rect\n","  contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    # get bounding rect info\n","  contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)           # calculate the contour area\n","  allContoursWithData.append(contourWithData)                                     # add contour with data object to list of all contours with data\n","# end for\n","\n","for contourWithData in allContoursWithData:                 # for all contours\n","  if contourWithData.checkIfContourIsValid():             # check if valid\n","    validContoursWithData.append(contourWithData)       # if so, append to valid contour list\n","# end if\n","# end for\n","\n","validContoursWithData.sort(key = operator.attrgetter(\"intRectX\"))         # sort contours from left to right\n","\n","strFinalString = \"\"         # declare final string, this will have the final number sequence by the end of the program\n","\n","for contourWithData in validContoursWithData:            # for each contour\n","                                              # draw a green rect around the current char\n","  cv2.rectangle(imgTestingNumbers,(contourWithData.intRectX, contourWithData.intRectY),(contourWithData.intRectX + contourWithData.intRectWidth, contourWithData.intRectY + contourWithData.intRectHeight),(0, 255, 0),2)                        # thickness\n","  imgROI = imgThresh[contourWithData.intRectY : contourWithData.intRectY + contourWithData.intRectHeight,  contourWithData.intRectX : contourWithData.intRectX + contourWithData.intRectWidth]\n","  imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))             # resize image, this will be more consistent for recognition and storage\n","  npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))      # flatten image into 1d numpy array\n","  npaROIResized = np.float32(npaROIResized)       # convert from 1d numpy array of ints to 1d numpy array of floats\n","  retval, npaResults, neigh_resp, dists = kNearest.findNearest(npaROIResized, k = 1)     # call KNN function find_nearest\n","  strCurrentChar = str(chr(int(npaResults[0][0])))\n","  strFinalString = strFinalString + strCurrentChar            # append current char to full string\n","    # end for\n","\n","print(\"\\n\" + strFinalString + \"\\n\")                 # show the full string\n","\n","cv2.imshow(\"imgTestingNumbers\", imgTestingNumbers)      # show input image with green boxes drawn around found digits\n","cv2.waitKey(0)                                          # wait for user key press\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["error: image not read from file \n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-2756719b04b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# end if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mimgGray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTestingNumbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# get grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mimgBlurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# blur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"metadata":{"id":"fjE2k77Ko0CW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}